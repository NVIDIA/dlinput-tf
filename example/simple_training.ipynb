{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple loading & training using zmq_ops\n",
    "\n",
    "using minst_server in tensorcom for sending data\n",
    "\n",
    "\n",
    "`\n",
    "python3 ./serve-mnist zpub://127.0.0.1:7880\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorcom\n",
    "from nvzmq_ops import ZmqOp\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BATCH_SIZE = 32\n",
    "_NUM_CLASS=10\n",
    "IMAGE_SIZE = 28\n",
    "_NUM_IMAGES = {'train': 60000,\n",
    "              'val': 10000}\n",
    "\n",
    "TYPES = [tf.dtypes.as_dtype(np.dtype('float16')), tf.dtypes.as_dtype(np.dtype('int32'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_items(types, is_train):\n",
    "    zmq_op = ZmqOp(address=\"zsub://127.0.0.1:7880\", zmq_hwm=200, zmq_buff=10240)\n",
    "    x, y = zmq_op.pull(types)\n",
    "    while True:\n",
    "        if is_train:\n",
    "            pass\n",
    "        x = tf.reshape(x, (_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE))\n",
    "        y = tf.one_hot(y, _NUM_CLASS)\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess =  tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float16 (32, 28, 28)\n",
      "float32 (32, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fffb3376c18>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, target = sess.run(next(load_items(TYPES, True)))\n",
    "print(type(data), data.dtype, data.shape)\n",
    "print(target.dtype, target.shape)\n",
    "plt.imshow(data[0].astype(\"float32\"), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_batches = _NUM_IMAGES['train'] // _BATCH_SIZE\n",
    "num_val_batches = _NUM_IMAGES['val'] // _BATCH_SIZE\n",
    "train_dataset = tf.data.Dataset.from_tensors(0).repeat().map(lambda _: next(load_items(TYPES, True)))\n",
    "val_dataset = tf.data.Dataset.from_tensors(0).repeat().map(lambda _: next(load_items(TYPES, False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter = train_dataset.make_initializable_iterator()\n",
    "# val_iter = val_dataset.make_initializable_iterator()\n",
    "# images, labels = train_iter.get_next()\n",
    "\n",
    "train_iter = train_dataset.make_one_shot_iterator()\n",
    "val_iter = val_dataset.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wendyh/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/wendyh/.local/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/wendyh/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2139 - acc: 0.9352\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1096 - acc: 0.9664\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0880 - acc: 0.9723\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0753 - acc: 0.9762\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0641 - acc: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fff90210a58>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_iter, epochs=5, steps_per_epoch=num_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 1s 4ms/step - loss: 0.0346 - acc: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03462819069460611, 0.9900841]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_dataset, steps=num_val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
